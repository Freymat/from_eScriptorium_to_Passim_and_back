{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1326896f",
   "metadata": {},
   "source": [
    "# Import Passim results into eScriptorium\n",
    "These scripts creates xml altos from Passim alignment results, for import into eScriptorium.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2b6c9",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6046d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import Levenshtein\n",
    "import zipfile  \n",
    "from pprint import pprint\n",
    "\n",
    "from functions import *\n",
    "from packages import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd735ee",
   "metadata": {},
   "source": [
    "### Extracting Passim's alignment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a43b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the document pk for interactions with the eSc API\n",
    "doc_pk = 4518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57ec23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams used in Passim\n",
    "n = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16a3addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein threshold for the Passim matches\n",
    "levenshtein_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1ea8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory containing the passim output\n",
    "path_passim_output = f'json_from_passim/out_n{n}_docwise/out.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cecfcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_list_from_passim_outputs(path_passim_output):\n",
    "    '''\n",
    "    Gather the Passim outputs from jsons into a list of dictionaries.\n",
    "    '''\n",
    "    # List to store data from all JSON files\n",
    "    out_passim_list = []\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for file in os.listdir(path_passim_output):\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(path_passim_output, file)\n",
    "            # Open the JSON file and load its content as a list of dictionaries\n",
    "            with open(file_path, 'r', encoding=\"utf-8\") as json_file:\n",
    "                data = [json.loads(line) for line in json_file]\n",
    "                out_passim_list.extend(data)\n",
    "    print(f\"Number of blocks to be processed:{len(out_passim_list)}\")\n",
    "    return out_passim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5e24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of GTs found in alignments:\n",
    "def list_GT_from_passim_output(out_passim_list):\n",
    "    '''\n",
    "    Get the GT present in Passim alignment results.\n",
    "    '''\n",
    "    GT_ids = list(set([wit['id']\n",
    "              for textblock in out_passim_list\n",
    "              for line in textblock['lines']\n",
    "              for wit in line.get('wits', [])]))\n",
    "    return GT_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "093c2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_alg_text(alg_text):\n",
    "    '''\n",
    "    Clean the text from the alignment.\n",
    "    '''\n",
    "    # clean the alignment text\n",
    "    # Replace '-' (45) with '', but avoid empty lines\n",
    "    alg_text = alg_text.replace('-', '') if alg_text.replace('-', '') else alg_text\n",
    "    # Replace '-' (8208) with '-' (45)\n",
    "    alg_text = alg_text.replace(chr(8208), '-')\n",
    "    # Remove leading and trailing spaces, but avoid empty lines\n",
    "    alg_text = alg_text.strip() if alg_text.strip() else alg_text\n",
    "    return alg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1878e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_passim_results(path_passim_output):\n",
    "    '''\n",
    "    Extracts the Passim alignments results and build a dictionary for each GT.\n",
    "    The dictionaries are updates of the ocr_lines_dict.json file.\n",
    "    For each ocr line where Passim found a GT, the GT is added with (among others) the following informations:\n",
    "    - the cleaned text of the GT (leading and trailing spaces removed, '-' (45) replaced with '', '-' (8208) replaced with '-' (45))\n",
    "    - the position of the first aligned character in the GT text\n",
    "    '''\n",
    "\n",
    "    # Gather Passim's results in a list\n",
    "    out_passim_list = build_list_from_passim_outputs(path_passim_output)\n",
    "\n",
    "    # list of GTs found in alignments:\n",
    "    GT_ids = list_GT_from_passim_output(out_passim_list)\n",
    "    print(f'list of GTs found in alignments: {GT_ids}')\n",
    "\n",
    "    # Iterate over GT_ids, and update the ocr_lines_dict with the GT alignment text\n",
    "    for GT_id in GT_ids:\n",
    "        print(f\"--- Processing of GT {GT_id} ---\")\n",
    "\n",
    "        # Load dictionary containing OCR line-splitting information\n",
    "        with open('ocr_lines_dict/ocr_lines_dict.json', 'r', encoding=\"utf-8\") as json_file:\n",
    "            ocr_lines_dict = json.load(json_file)\n",
    "        \n",
    "        # Iterate over out_passim_list dictionaries\n",
    "        for textblock in out_passim_list:\n",
    "\n",
    "            # Extract the filename and textblock_id\n",
    "            textblock_id = re.sub(r'.*(eSc_textblock_[a-f0-9]+).*', r'\\1', textblock['id'])\n",
    "            filename = re.sub(r'.*' + textblock_id + '_(.*)', r'\\1', textblock['id'])\n",
    "\n",
    "            for line in textblock['lines']:\n",
    "                begin_index = line['begin']\n",
    "                # Check if the current GT_id is present in the wits of the line\n",
    "                for wit in line.get('wits', []):\n",
    "                    if wit['id'] == GT_id:\n",
    "                        alg_text = wit['alg']\n",
    "                        alg_text = clean_alg_text(alg_text)\n",
    "                        GT_start = wit['begin']\n",
    "                        GT_length = len(wit['text'])\n",
    "\n",
    "                        # Find the corresponding line in the OCR dictionary\n",
    "                        for part in ocr_lines_dict:\n",
    "                            if part['filename'] == filename:\n",
    "                                for block in part['ocr_blocks']:\n",
    "                                    if block['text_block_id'] == textblock_id:\n",
    "                                        for ocr_line in block['ocr_lines']:\n",
    "                                            if ocr_line['start'] == begin_index:\n",
    "                                                # Update the OCR line with the GT alignment text\n",
    "                                                ocr_line['alg_GT'] = alg_text\n",
    "                                                ocr_line['GT_id'] = GT_id\n",
    "                                                ocr_line['GT_start'] = GT_start\n",
    "                                                ocr_line['GT_len'] = GT_length\n",
    "                                                lev_ratio = Levenshtein.ratio(alg_text, ocr_line['text'])\n",
    "                                                ocr_line['levenshtein_ratio'] = round(lev_ratio, 3)\n",
    "                                                break  # No need to continue searching once found\n",
    "\n",
    "        # Save a JSON file for each GT_id\n",
    "        directory = 'lines_dict_with_alg_GT'\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        file_path = os.path.join(directory, f'lines_dict_with_alg_{GT_id}.json')\n",
    "        with open(file_path, 'w', encoding=\"utf-8\") as json_file:\n",
    "            json.dump(ocr_lines_dict, json_file, ensure_ascii=False, indent=4)\n",
    "        print(f\"    File {file_path} saved.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfebaa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks to be processed:61\n",
      "list of GTs found in alignments: ['Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt', 'Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt', 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt', 'Siddur_Ashkenaz_clean_concatenated.txt', 'MT_NoVoc_concatenated.txt']\n",
      "--- Processing of GT Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt.json saved.\n",
      "--- Processing of GT Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Siddur_Ashkenaz_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Siddur_Ashkenaz_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT MT_NoVoc_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_MT_NoVoc_concatenated.txt.json saved.\n"
     ]
    }
   ],
   "source": [
    "# extract_passim_results(path_passim_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22c763",
   "metadata": {},
   "source": [
    "### Parsing XML files and updating text content with GT alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04e4487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the alto files from eScriptorium\n",
    "path_xmls_from_eSc = 'xmls_from_eSc'\n",
    "\n",
    "# Path to the output directory, where the new alto files (and zip) will be saved\n",
    "path_xmls_for_eSc = 'xmls_for_eSc'\n",
    "\n",
    "# Path to directory containing the dictionaries with the alignment of the GT for each OCR line\n",
    "path_alg_dicts = 'lines_dict_with_alg_GT'\n",
    "\n",
    "# Path to the directory containing the information about all parts of the document\n",
    "path_all_parts_infos = 'eSc_parts_infos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcc2493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_alignment_register_to_json(alignment_register):\n",
    "    '''Save the alignment register in a JSON file.'''\n",
    "    output_folder = 'alignment_register/'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    register_file_path = os.path.join(output_folder, 'alignment_register.json')\n",
    "    with open(register_file_path, 'w', encoding=\"utf-8\") as json_file:\n",
    "        json.dump(alignment_register, json_file, ensure_ascii=False, indent=4)\n",
    "    return alignment_register\n",
    "\n",
    "def get_xml_files_with_alignment(lines_dict, GT_id):\n",
    "    '''Get XML files containing alignments for a given ID.'''\n",
    "    xml_files_with_alg = set()\n",
    "    for part in lines_dict:\n",
    "        for block in part['ocr_blocks']:\n",
    "            for line in block['ocr_lines']:\n",
    "                if line.get('alg_GT') and line['GT_id'] == GT_id:\n",
    "                    xml_files_with_alg.add(part['filename'])\n",
    "    return list(xml_files_with_alg)\n",
    "\n",
    "def process_alignment_xml_as_txt(path_alg_dicts, path_alto, path_xmls_from_eSc, levenshtein_threshold):\n",
    "    '''Process the alignment of the GT on the OCR text lines and save the modified XML files in a ZIP archive.'''\n",
    "    alignment_register = []\n",
    "\n",
    "    for json_file in os.listdir(path_alg_dicts):\n",
    "        if json_file.endswith('.json'):\n",
    "            with open(os.path.join(path_alg_dicts, json_file), 'r', encoding=\"utf-8\") as json_file_handler:\n",
    "                lines_dict = json.load(json_file_handler)\n",
    "            id2 = re.sub(r'lines_dict_with_alg_(.*).json', r'\\1', json_file)\n",
    "            output_folder = os.path.join(path_alto, id2)\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "            xml_files_with_alg = get_xml_files_with_alignment(lines_dict, id2)\n",
    "\n",
    "            for xml_file in os.listdir(path_xmls_from_eSc):\n",
    "                if xml_file.endswith('.xml'):\n",
    "                    if os.path.splitext(xml_file)[0] not in xml_files_with_alg:\n",
    "                        continue\n",
    "                    # Create a list of tuples with all detected alignments for the current GT\n",
    "                    # If, the alignment is considered valid  with a Levenshtein ratio above the threshold\n",
    "                    # the GT will be added to the XML file\n",
    "                    # Otherwise, the content of the OCR line will be updated to an empty string\n",
    "                    \n",
    "                    line_ids_with_GT = [(line['line_id'], line['alg_GT'], line['levenshtein_ratio']) \n",
    "                                        for part in lines_dict \n",
    "                                        if part['filename'] == os.path.splitext(xml_file)[0]\n",
    "                                        for block in part['ocr_blocks']\n",
    "                                        for line in block['ocr_lines']\n",
    "                                        if line.get('alg_GT') and line['GT_id'] == id2]\n",
    "\n",
    "                    with open(os.path.join(path_xmls_from_eSc, xml_file), encoding=\"utf-8\") as xml_file_handler:\n",
    "                        xml_as_txt = xml_file_handler.read()\n",
    "\n",
    "                    line_count = 0\n",
    "\n",
    "                    xml_text_lines = re.findall(r'<TextLine ID=\".*?\".*?</TextLine>', xml_as_txt, re.DOTALL)\n",
    "                    for xml_text_line in xml_text_lines:\n",
    "                        xml_text_line_id = re.search(r'<TextLine ID=\"(.*?)\"', xml_text_line).group(1)\n",
    "                        if xml_text_line_id not in [line_id for line_id, _, _ in line_ids_with_GT]:\n",
    "                            updated_content = re.sub(r'<String CONTENT=\".*?\"', '<String CONTENT=\"\"', xml_text_line)\n",
    "                            xml_as_txt = xml_as_txt.replace(xml_text_line, updated_content)\n",
    "                        else:\n",
    "                            for text_line_id, alg_GT, levenshtein_ratio in line_ids_with_GT:                                \n",
    "                                if text_line_id == xml_text_line_id:\n",
    "                                    string_content_match = re.search(r'<String CONTENT=\"(.*?)\"', xml_text_line)\n",
    "                                    if string_content_match:\n",
    "                                        if levenshtein_ratio >= levenshtein_threshold:\n",
    "                                            new_content = f'CONTENT=\"{alg_GT}\"'\n",
    "                                            line_count += 1\n",
    "                                        else:\n",
    "                                            new_content = 'CONTENT=\"\"'\n",
    "                                        xml_as_txt = xml_as_txt.replace(string_content_match.group(0), f'<String {new_content}')\n",
    "\n",
    "                    if line_count > 0:\n",
    "                        alignment_register.append({\n",
    "                            'filename': xml_file,\n",
    "                            'aligned_lines_count': line_count,\n",
    "                            'GT_id': id2\n",
    "                        })\n",
    "\n",
    "                    output_file_path = os.path.join(output_folder, xml_file)\n",
    "                    with open(output_file_path, 'w', encoding=\"utf-8\") as output_file:\n",
    "                        output_file.write(xml_as_txt)\n",
    "\n",
    "    zip_alignment_files(path_alto, alignment_register)\n",
    "\n",
    "    save_alignment_register_to_json(alignment_register)\n",
    "\n",
    "    return alignment_register\n",
    "\n",
    "def zip_alignment_files(path_alto, alignment_register):\n",
    "    for id2 in set(entry['GT_id'] for entry in alignment_register):\n",
    "        output_folder = os.path.join(path_alto, id2)\n",
    "        zip_file_name = f\"{id2}_alignment.zip\"\n",
    "        zip_file_path = os.path.join(path_alto, zip_file_name)\n",
    "        with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "            for root, _, files in os.walk(output_folder):\n",
    "                for file in files:\n",
    "                    zipf.write(os.path.join(root, file), arcname=file)\n",
    "        print(f\"XML files in {output_folder} compressed in {zip_file_path}\")\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the process_alignment function\n",
    "# process_alignment_xml_as_txt(path_alg_dicts, path_xmls_for_eSc, path_xmls_from_eSc, levenshtein_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6607de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_passim_results(path_passim_output, path_alg_dicts, path_xmls_from_eSc, path_xmls_for_eSc, levenshtein_threshold):\n",
    "    '''\n",
    "    This global function processes the Passim results and updates the XML alto files with the GT alignment.\n",
    "    - Extracts the Passim alignment results\n",
    "    - Parse the XML files from eScriptorium, and update the OCR lines with the GT alignment\n",
    "    if the levenshtein ratio between the OCR and GT textblocks containing the lines is above a given threshold.\n",
    "    - Save the updated XML files in a ZIP archive, ready to be sent to eScriptorium.\n",
    "    Parameters:\n",
    "    path_passim_output (str): Path to the directory containing the Passim output JSON files\n",
    "    path_alg_dicts (str): Path to the directory containing the dictionaries with the alignment of the different GT, for each OCR line\n",
    "    path_xmls_from_eSc (str): Path to the directory containing the alto files from eScriptorium\n",
    "    path_xmls_for_eSc (str): Path to the output directory, where the new alto files (and zip) will be saved\n",
    "    '''\n",
    "\n",
    "    # Extract the Passim alignment results\n",
    "    extract_passim_results(path_passim_output)\n",
    "    # Parse the XML files from eScriptorium, and update the OCR lines with the GT alignment if the levenshtein ratio is above a given threshold\n",
    "    process_alignment_xml_as_txt(path_alg_dicts, path_xmls_for_eSc, path_xmls_from_eSc, levenshtein_threshold)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f456182",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocess_alignment_xml_as_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_alg_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_xmls_for_eSc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_xmls_from_eSc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevenshtein_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 58\u001b[0m, in \u001b[0;36mprocess_alignment_xml_as_txt\u001b[0;34m(path_alg_dicts, path_alto, path_xmls_from_eSc, levenshtein_threshold)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xml_text_line \u001b[38;5;129;01min\u001b[39;00m xml_text_lines:\n\u001b[1;32m     57\u001b[0m     xml_text_line_id \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<TextLine ID=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, xml_text_line)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xml_text_line_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [line_id \u001b[38;5;28;01mfor\u001b[39;00m line_id, _, _, _ \u001b[38;5;129;01min\u001b[39;00m line_ids_with_GT]:\n\u001b[1;32m     59\u001b[0m         updated_content \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<String CONTENT=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<String CONTENT=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, xml_text_line)\n\u001b[1;32m     60\u001b[0m         xml_as_txt \u001b[38;5;241m=\u001b[39m xml_as_txt\u001b[38;5;241m.\u001b[39mreplace(xml_text_line, updated_content)\n",
      "Cell \u001b[0;32mIn[16], line 58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xml_text_line \u001b[38;5;129;01min\u001b[39;00m xml_text_lines:\n\u001b[1;32m     57\u001b[0m     xml_text_line_id \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<TextLine ID=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, xml_text_line)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xml_text_line_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [line_id \u001b[38;5;28;01mfor\u001b[39;00m line_id, _, _, _ \u001b[38;5;129;01min\u001b[39;00m line_ids_with_GT]:\n\u001b[1;32m     59\u001b[0m         updated_content \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<String CONTENT=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<String CONTENT=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, xml_text_line)\n\u001b[1;32m     60\u001b[0m         xml_as_txt \u001b[38;5;241m=\u001b[39m xml_as_txt\u001b[38;5;241m.\u001b[39mreplace(xml_text_line, updated_content)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "process_alignment_xml_as_txt(path_alg_dicts, path_xmls_for_eSc, path_xmls_from_eSc, levenshtein_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13117a1b",
   "metadata": {},
   "source": [
    "### Build tsv files for results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34995a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to count the maximum number of succesive aligned lines\n",
    "# La fonction me retourne le nombre maximum de lignes alignées successives pour un GT donné, pour un fichier donné, en fonction d'un seuil de Levenshtein\n",
    "def count_max_successive_aligned_lines(lines_dict, filename, levenshtein_threshold):\n",
    "    '''Count the maximum number of successive aligned lines for a given GT.'''\n",
    "    max_successive_aligned_lines = 0\n",
    "    successive_aligned_lines = 0\n",
    "    for part in lines_dict:\n",
    "        if part['filename'] != filename:\n",
    "            continue        \n",
    "        for block in part['ocr_blocks']:\n",
    "\n",
    "            for line in block['ocr_lines']:\n",
    "                if line.get('alg_GT') and line['levenshtein_ratio'] >= levenshtein_threshold:\n",
    "                    successive_aligned_lines += 1\n",
    "                    if successive_aligned_lines > max_successive_aligned_lines:\n",
    "                        max_successive_aligned_lines = successive_aligned_lines\n",
    "                else:\n",
    "                    successive_aligned_lines = 0\n",
    "    return max_successive_aligned_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339e0957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dict_path = 'lines_dict_with_alg_GT/lines_dict_with_alg_MT_NoVoc_concatenated.txt.json'\n",
    "filename = 'IE61220167_00083'\n",
    "levenshtein_threshold = 0.8\n",
    "\n",
    "with open(lines_dict_path, 'r', encoding=\"utf-8\") as json_file:\n",
    "    lines_dict = json.load(json_file)\n",
    "\n",
    "count_max_successive_aligned_lines(lines_dict, filename, levenshtein_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12adfcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignment_register(alignment_register_path=\"alignment_register/alignment_register.json\"):\n",
    "    \"\"\"\n",
    "    Load the alignment register from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(alignment_register_path, 'r', encoding=\"utf-8\") as json_file_handler:\n",
    "        return json.load(json_file_handler)\n",
    "    \n",
    "\n",
    "\n",
    "def create_aligned_counts_by_image(alignment_register):\n",
    "    \"\"\"\n",
    "    Create a dictionary with aligned lines counts for each image and GT.\n",
    "    \"\"\"\n",
    "    # Collect all unique GT_ids\n",
    "    gt_ids = sorted(set(entry[\"GT_id\"] for entry in alignment_register))\n",
    "    \n",
    "    # Initialize a dictionary to hold aligned lines counts for each image\n",
    "    aligned_counts_by_image = {entry[\"filename\"]: {gt_id: 0 for gt_id in gt_ids} for entry in alignment_register}\n",
    "    \n",
    "    # Fill the dictionary\n",
    "    for entry in alignment_register:\n",
    "        filename = entry[\"filename\"]\n",
    "        gt_id = entry[\"GT_id\"]\n",
    "        aligned_lines_count = entry[\"aligned_lines_count\"]\n",
    "        aligned_counts_by_image[filename][gt_id] = aligned_lines_count\n",
    "    \n",
    "    return aligned_counts_by_image\n",
    "\n",
    "def identify_top_n_best_gt(aligned_counts_by_image, n_best_gt):\n",
    "    \"\"\" \n",
    "    Identify the n best GTs for each image based on the number of aligned lines.\n",
    "    Parameters:\n",
    "    - aligned_counts_by_image: dictionary with aligned lines counts for each image and GT\n",
    "    - n_best_gt: number of best GTs to identify\n",
    "    \"\"\"\n",
    "    top_n_best_gt = {}\n",
    "    for filename, gt_counts in aligned_counts_by_image.items():\n",
    "        # Sort GTs by aligned lines count\n",
    "        sorted_gt_counts = sorted(gt_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        # Take top n GTs\n",
    "        top_n_gt_counts = sorted_gt_counts[:n_best_gt]\n",
    "        top_n_best_gt[filename] = [(gt_id, aligned_lines_count) for gt_id, aligned_lines_count in top_n_gt_counts]\n",
    "    return top_n_best_gt\n",
    "\n",
    "def get_nb_of_ocr_lines_in_file(filename):\n",
    "    \"\"\"\n",
    "    Get the number of OCR lines in the file from the filename.\n",
    "    Parameters:\n",
    "    - filename of the image. Extension should be .jpg, but the function\n",
    "    handles the case where the extension is missing or different.\n",
    "    \"\"\"\n",
    "    # Load dictionary containing OCR line-splitting information\n",
    "    with open('ocr_lines_dict/ocr_lines_dict.json', 'r', encoding=\"utf-8\") as json_file:\n",
    "        ocr_lines_dict = json.load(json_file)\n",
    "    \n",
    "    filename, extension = os.path.splitext(filename)\n",
    "\n",
    "    for file in ocr_lines_dict:\n",
    "        if file['filename'] == filename:            \n",
    "            nb_of_ocr_lines = file['ocr_lines_in_part']\n",
    "            break\n",
    "    return nb_of_ocr_lines\n",
    "\n",
    "def load_all_parts_infos():\n",
    "    \"\"\"\n",
    "    Get all parts informations from the folder 'eSc_parts_infos'.\n",
    "    \"\"\"\n",
    "    with open(f\"{path_all_parts_infos}/all_parts_infos.json\", 'r', encoding=\"utf-8\") as json_file:\n",
    "        all_parts_infos = json.load(json_file)\n",
    "\n",
    "    return all_parts_infos\n",
    "\n",
    "def get_pk_from_filename(all_parts_infos, filename): # We don't insert the function load_all_parts_infos in this function to avoid multiple requests\n",
    "    \"\"\"\n",
    "    Function to get the pk and the title in eScriptorium of a part from its filename.\n",
    "    Parameters:\n",
    "    - all_parts_infos: list of dictionaries containing informations about the parts.\n",
    "    requested from the eScriptorium API. This dictionnary is requested (all_parts_infos = get_all_parts(doc_pk))\n",
    "    from the eScriptorium API outisde of this function to avoid multiple requests.\n",
    "    - filename of the image. Extension should be .jpg, but the function\n",
    "    handles the case where the extension is missing or different.\n",
    "    \"\"\"\n",
    "    filename, extension = os.path.splitext(filename)    \n",
    "    for item in all_parts_infos:\n",
    "        if item['filename'] == filename + '.jpg':\n",
    "            return (item['pk'], item['title'])\n",
    "    return (None, None)\n",
    "\n",
    "def create_tsv(aligned_counts_by_image, doc_pk, top_n_best_gt, display_n_best_gt, n_best_gt):\n",
    "    \"\"\"\n",
    "    Create a TSV file with aligned lines counts for each GT and image.\n",
    "    If display_n_best_gt is True, include columns for the n best GTs with most aligned lines.\n",
    "    The TSV is based on the aligned_counts_by_image dictionary.        \n",
    "    \"\"\"\n",
    "    # Collect all unique GT_ids\n",
    "    gt_ids = sorted(set(gt_id for gt_counts in aligned_counts_by_image.values() for gt_id in gt_counts.keys()))\n",
    "\n",
    "    # Update TSV header\n",
    "    tsv_header = \"count\\tdoc_pk\\tfilename\\tpart_pk\\ttitle\\tnb_of_ocr_lines\\t\"  # Modified header to include nb_of_ocr_lines\n",
    "    if display_n_best_gt:\n",
    "        tsv_header += \"\\t\".join(f\"best_GT_{i}_id\\tbest_GT_{i}_aligned_lines_count\" for i in range(1, n_best_gt + 1)) + \"\\t\"\n",
    "    tsv_header += \"\\t\".join(gt_ids) + \"\\n\"\n",
    "    \n",
    "    # Create TSV rows\n",
    "    tsv_rows = \"\"\n",
    "    all_parts_infos = load_all_parts_infos()\n",
    "    count = 1  # Initialize counter\n",
    "    for filename, gt_counts in aligned_counts_by_image.items():\n",
    "        # Retrieve the number of OCR lines in the file\n",
    "        nb_of_ocr_lines = get_nb_of_ocr_lines_in_file(filename)\n",
    "\n",
    "        # Retrieve PK and title based on filename\n",
    "        part_pk, title = get_pk_from_filename(all_parts_infos, filename)\n",
    "\n",
    "        # Make sure part_pk and title are never None\n",
    "        part_pk = part_pk if part_pk is not None else 'N/A'\n",
    "        title = title if title is not None else 'N/A'\n",
    "\n",
    "        # Add count, doc_pk, part_pk, title, nb_of_ocr_lines\n",
    "        row = f\"{count}\\t{doc_pk}\\t{filename}\\t{part_pk}\\t{title}\\t{nb_of_ocr_lines}\\t\"\n",
    "        count += 1\n",
    "        \n",
    "        if display_n_best_gt:\n",
    "            if filename in top_n_best_gt:\n",
    "                for i in range(1, n_best_gt + 1):\n",
    "                    gt_id, aligned_lines_count = top_n_best_gt[filename][i-1] if i-1 < len(top_n_best_gt[filename]) else ('', '')\n",
    "                    row += f\"{gt_id}\\t{aligned_lines_count}\\t\"\n",
    "            else:\n",
    "                row += '\\t' * (n_best_gt * 2)\n",
    "                \n",
    "        for gt_id in gt_ids:\n",
    "            row += str(gt_counts.get(gt_id, '')) + \"\\t\"\n",
    "        tsv_rows += row.strip() + \"\\n\"\n",
    "    \n",
    "    return tsv_header + tsv_rows\n",
    "\n",
    "def create_tsv_from_alignment_register(alignment_register, doc_pk, display_n_best_gt=True, n_best_gt=1):\n",
    "    \"\"\"\n",
    "    Create a TSV file with the number of aligned lines for each GT and image.\n",
    "    This function can give the n best GT for each image.\n",
    "    Rows: one row per image (filename from the XML file)\n",
    "    Columns:\n",
    "    - one column per Ground Truth (GT_ids)\n",
    "    - one column with the number of aligned lines for the best GT\n",
    "    - additional columns for n best GTs with most aligned lines (optional)\n",
    "    \"\"\"\n",
    "    aligned_counts_by_image = create_aligned_counts_by_image(alignment_register)\n",
    "    top_n_best_gt = identify_top_n_best_gt(aligned_counts_by_image, n_best_gt)\n",
    "    tsv_content = create_tsv(aligned_counts_by_image, doc_pk, top_n_best_gt, display_n_best_gt, n_best_gt)\n",
    "\n",
    "    # Ensure the results directory exists\n",
    "    results_dir = 'results_summary_tsv'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "    # Write to file in the results directory\n",
    "    tsv_file_path = os.path.join(results_dir, f\"alignment_data_doc_pk_{doc_pk}_n{n}_lev_{levenshtein_threshold}.tsv\")\n",
    "    with open(tsv_file_path, \"w\") as tsv_file:\n",
    "        tsv_file.write(tsv_content)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9117c9a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alignment_register' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# alignment_register = load_alignment_register(alignment_register_path=\"alignment_register/alignment_register.json\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m create_tsv_from_alignment_register(\u001b[43malignment_register\u001b[49m,doc_pk, display_n_best_gt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_best_gt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alignment_register' is not defined"
     ]
    }
   ],
   "source": [
    "# alignment_register = load_alignment_register(alignment_register_path=\"alignment_register/alignment_register.json\")\n",
    "# create_tsv_from_alignment_register(alignment_register,doc_pk, display_n_best_gt=True, n_best_gt=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f37cd5",
   "metadata": {},
   "source": [
    "# Run the complete pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90ce4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks to be processed:639\n",
      "list of GTs found in alignments: ['Mishnah_Kiddushin_clean_concatenated.txt', 'Yalkut_Shimoni_on_Nach_clean_concatenated.txt', 'Mishnah_Bava_Metzia_clean_concatenated.txt', 'MT_NoVoc_concatenated.txt', 'Pirkei_Avot_clean_concatenated.txt', 'Mishnah_Shekalim_clean_concatenated.txt', 'Hadran_for_Tanakh_clean_concatenated.txt', 'Machzor_Rosh_Hashanah_Ashkenaz_Linear_clean_concatenated.txt', 'Ruth_Rabbah_clean_concatenated.txt', 'Midrash_Tanchuma_clean_concatenated.txt', \"Ma'aneh_Lashon_Chabad_clean_concatenated.txt\", 'Mishnah_Kelim_clean_concatenated.txt', 'Machzor_Rosh_Hashanah_Sefard_clean_concatenated.txt', 'Midrash_Tehillim_clean_concatenated.txt', 'Birkat_Hamazon_clean_concatenated.txt', 'Esther_Rabbah_clean_concatenated.txt', 'Tikkun_HaKlali_clean_concatenated.txt', 'Mishnah_Makhshirin_clean_concatenated.txt', 'Mishnah_Shabbat_clean_concatenated.txt', 'Weekday_Siddur_Chabad_clean_concatenated.txt', 'Seder_Olam_Rabbah_clean_concatenated.txt', 'Mishnah_Yevamot_clean_concatenated.txt', 'Machzor_Rosh_Hashanah_Edot_HaMizrach_clean_concatenated.txt', 'Mishnah_Megillah_clean_concatenated.txt', 'Ein_Yaakov_clean_concatenated.txt', 'Sifrei_Bamidbar_clean_concatenated.txt', 'Bamidbar_Rabbah_clean_concatenated.txt', 'Mishnah_Sanhedrin_clean_concatenated.txt', 'Mishnat_Rabbi_Eliezer_clean_concatenated.txt', 'Pirkei_DeRabbi_Eliezer_clean_concatenated.txt', 'Aggadat_Bereshit_clean_concatenated.txt', 'Pesach_Haggadah_clean_concatenated.txt', 'Mishnah_Zevachim_clean_concatenated.txt', 'Talmud_Jerusalem.txt', 'Mishnah_Makkot_clean_concatenated.txt', 'Lekha_Dodi_clean_concatenated.txt', 'Mishnah_Shevuot_clean_concatenated.txt', 'Midrash_Sekhel_Tov_clean_concatenated.txt', 'Ruth_Rabbah_(Lerner)_clean_concatenated.txt', 'Talmud_Babylon.txt', 'Mishnah_Middot_clean_concatenated.txt', 'Sifrei_Aggadah_on_Esther_clean_concatenated.txt', 'Shir_HaShirim_Rabbah_clean_concatenated.txt', 'Mishnah_Demai_clean_concatenated.txt', 'Tanna_DeBei_Eliyahu_Rabbah_clean_concatenated.txt', 'Yalkut_Shimoni_on_Torah_clean_concatenated.txt', 'Ein_Yaakov_(Glick_Edition)_clean_concatenated.txt', 'Keter_Malkhut_clean_concatenated.txt', 'Devarim_Rabbah_clean_concatenated.txt', 'Mishnah_Peah_clean_concatenated.txt', 'Perek_Shirah_clean_concatenated.txt', 'Kabbalat_Shabbat_clean_concatenated.txt', 'Shabbat_Siddur_Sefard_Linear_clean_concatenated.txt', 'Mishnah_Terumot_clean_concatenated.txt', 'Bereshit_Rabbati_clean_concatenated.txt', 'Mishnah_Eduyot_clean_concatenated.txt', 'Mishnah_Bava_Kamma_clean_concatenated.txt', 'Midrash_Tanchuma_Buber_clean_concatenated.txt', 'Leshon_Chakhamim_clean_concatenated.txt', 'Mishnah_Pesachim_clean_concatenated.txt', 'Pesach_Haggadah_Edot_Hamizrah_clean_concatenated.txt', 'Mishnah_Rosh_Hashanah_clean_concatenated.txt', 'Siddur_Edot_HaMizrach_clean_concatenated.txt', 'Pesikta_Rabbati_clean_concatenated.txt', 'Midrash_Tannaim_on_Deuteronomy_clean_concatenated.txt', 'Shir_HaKavod_clean_concatenated.txt', 'Mishnah_Negaim_clean_concatenated.txt', 'Hallel_clean_concatenated.txt', 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt', 'Vayikra_Rabbah_clean_concatenated.txt', 'Tanna_debei_Eliyahu_Zuta_clean_concatenated.txt', 'Midrash_Mishlei_clean_concatenated.txt', \"Seder_Ma'amadot_clean_concatenated.txt\", 'Mishnah_Yadayim_clean_concatenated.txt', 'Mishnah_Nedarim_clean_concatenated.txt', 'Pesikta_DeRav_Kahana_clean_concatenated.txt', 'Midrash_Yelamdenu,_Selections_from_Yalkut_Talmud_Torah_clean_concatenated.txt', 'Sifrei_Devarim_clean_concatenated.txt', 'Midrash_Shmuel_clean_concatenated.txt', 'Mekhilta_DeRabbi_Shimon_Ben_Yochai_clean_concatenated.txt', 'Sefer_HaYashar_(midrash)_clean_concatenated.txt', 'Machzor_Yom_Kippur_Edot_HaMizrach_clean_concatenated.txt', 'Mishnah_Berakhot_clean_concatenated.txt', 'Mishnah_Gittin_clean_concatenated.txt', 'Mishnah_Sotah_clean_concatenated.txt', 'Bereshit_Rabbah_clean_concatenated.txt', 'Selichot_Edot_HaMizrach_clean_concatenated.txt', 'Midrash_Lekach_Tov_on_Ruth_clean_concatenated.txt', 'Mishnah_Niddah_clean_concatenated.txt', \"Mishnah_Ta'anit_clean_concatenated.txt\", 'Kohelet_Rabbah_clean_concatenated.txt', 'Hadran_clean_concatenated.txt', \"Seder_Tisha_B'Av_(Edot_HaMizrach)_clean_concatenated.txt\", 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt', 'Mishnah_Eruvin_clean_concatenated.txt', 'Mishnah_Menachot_clean_concatenated.txt', 'Eikhah_Rabbah_clean_concatenated.txt', 'Mekhilta_DeRabbi_Yishmael_clean_concatenated.txt', 'Machzor_Yom_Kippur_Ashkenaz_Linear_clean_concatenated.txt', 'Siddur_Ashkenaz_clean_concatenated.txt', 'Mishnah_Tamid_clean_concatenated.txt', 'Sifrei_Zuta_clean_concatenated.txt', 'Sifra_clean_concatenated.txt', 'Shemot_Rabbah_clean_concatenated.txt', 'Weekday_Siddur_Sefard_Linear_clean_concatenated.txt', 'Machzor_Yom_Kippur_Sefard_clean_concatenated.txt', 'Otzar_Midrashim_clean_concatenated.txt', 'Siddur_Sefard_clean_concatenated.txt', 'Mishnah_Bava_Batra_clean_concatenated.txt']\n",
      "--- Processing of GT Mishnah_Kiddushin_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Kiddushin_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Yalkut_Shimoni_on_Nach_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Yalkut_Shimoni_on_Nach_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Bava_Metzia_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Bava_Metzia_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT MT_NoVoc_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_MT_NoVoc_concatenated.txt.json saved.\n",
      "--- Processing of GT Pirkei_Avot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Pirkei_Avot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Shekalim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Shekalim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Hadran_for_Tanakh_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Hadran_for_Tanakh_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Rosh_Hashanah_Ashkenaz_Linear_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Rosh_Hashanah_Ashkenaz_Linear_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Ruth_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Ruth_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Tanchuma_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Tanchuma_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Ma'aneh_Lashon_Chabad_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Ma'aneh_Lashon_Chabad_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Kelim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Kelim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Rosh_Hashanah_Sefard_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Rosh_Hashanah_Sefard_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Tehillim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Tehillim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Birkat_Hamazon_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Birkat_Hamazon_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Esther_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Esther_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Tikkun_HaKlali_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Tikkun_HaKlali_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Makhshirin_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Makhshirin_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Shabbat_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Shabbat_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Weekday_Siddur_Chabad_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Weekday_Siddur_Chabad_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Seder_Olam_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Seder_Olam_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Yevamot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Yevamot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Rosh_Hashanah_Edot_HaMizrach_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Rosh_Hashanah_Edot_HaMizrach_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Megillah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Megillah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Ein_Yaakov_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Ein_Yaakov_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Sifrei_Bamidbar_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Sifrei_Bamidbar_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Bamidbar_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Bamidbar_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Sanhedrin_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Sanhedrin_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnat_Rabbi_Eliezer_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnat_Rabbi_Eliezer_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Pirkei_DeRabbi_Eliezer_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Pirkei_DeRabbi_Eliezer_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Aggadat_Bereshit_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Aggadat_Bereshit_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Pesach_Haggadah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Pesach_Haggadah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Zevachim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Zevachim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Talmud_Jerusalem.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Talmud_Jerusalem.txt.json saved.\n",
      "--- Processing of GT Mishnah_Makkot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Makkot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Lekha_Dodi_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Lekha_Dodi_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Shevuot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Shevuot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Sekhel_Tov_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Sekhel_Tov_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Ruth_Rabbah_(Lerner)_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Ruth_Rabbah_(Lerner)_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Talmud_Babylon.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Talmud_Babylon.txt.json saved.\n",
      "--- Processing of GT Mishnah_Middot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Middot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Sifrei_Aggadah_on_Esther_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Sifrei_Aggadah_on_Esther_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Shir_HaShirim_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Shir_HaShirim_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Demai_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Demai_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Tanna_DeBei_Eliyahu_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Tanna_DeBei_Eliyahu_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Yalkut_Shimoni_on_Torah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Yalkut_Shimoni_on_Torah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Ein_Yaakov_(Glick_Edition)_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Ein_Yaakov_(Glick_Edition)_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Keter_Malkhut_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Keter_Malkhut_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Devarim_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Devarim_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Peah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Peah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Perek_Shirah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Perek_Shirah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Kabbalat_Shabbat_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Kabbalat_Shabbat_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Shabbat_Siddur_Sefard_Linear_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Shabbat_Siddur_Sefard_Linear_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Terumot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Terumot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Bereshit_Rabbati_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Bereshit_Rabbati_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Eduyot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Eduyot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Bava_Kamma_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Bava_Kamma_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Tanchuma_Buber_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Tanchuma_Buber_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Leshon_Chakhamim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Leshon_Chakhamim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Pesachim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Pesachim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Pesach_Haggadah_Edot_Hamizrah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Pesach_Haggadah_Edot_Hamizrah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Rosh_Hashanah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Rosh_Hashanah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Siddur_Edot_HaMizrach_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Siddur_Edot_HaMizrach_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Pesikta_Rabbati_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Pesikta_Rabbati_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Tannaim_on_Deuteronomy_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Tannaim_on_Deuteronomy_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Shir_HaKavod_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Shir_HaKavod_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Negaim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Negaim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Hallel_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Hallel_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Vayikra_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Vayikra_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Tanna_debei_Eliyahu_Zuta_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Tanna_debei_Eliyahu_Zuta_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Mishlei_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Mishlei_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Seder_Ma'amadot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Seder_Ma'amadot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Yadayim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Yadayim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Nedarim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Nedarim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Pesikta_DeRav_Kahana_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Pesikta_DeRav_Kahana_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Yelamdenu,_Selections_from_Yalkut_Talmud_Torah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Yelamdenu,_Selections_from_Yalkut_Talmud_Torah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Sifrei_Devarim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Sifrei_Devarim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Shmuel_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Shmuel_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mekhilta_DeRabbi_Shimon_Ben_Yochai_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mekhilta_DeRabbi_Shimon_Ben_Yochai_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Sefer_HaYashar_(midrash)_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Sefer_HaYashar_(midrash)_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Yom_Kippur_Edot_HaMizrach_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Yom_Kippur_Edot_HaMizrach_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Berakhot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Berakhot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Gittin_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Gittin_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Sotah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Sotah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Bereshit_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Bereshit_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Selichot_Edot_HaMizrach_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Selichot_Edot_HaMizrach_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Midrash_Lekach_Tov_on_Ruth_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Midrash_Lekach_Tov_on_Ruth_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Niddah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Niddah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Ta'anit_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Ta'anit_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Kohelet_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Kohelet_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Hadran_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Hadran_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Seder_Tisha_B'Av_(Edot_HaMizrach)_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Seder_Tisha_B'Av_(Edot_HaMizrach)_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Eruvin_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Eruvin_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Menachot_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Menachot_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Eikhah_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Eikhah_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mekhilta_DeRabbi_Yishmael_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mekhilta_DeRabbi_Yishmael_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Yom_Kippur_Ashkenaz_Linear_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Yom_Kippur_Ashkenaz_Linear_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Siddur_Ashkenaz_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Siddur_Ashkenaz_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Tamid_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Tamid_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Sifrei_Zuta_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Sifrei_Zuta_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Sifra_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Sifra_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Shemot_Rabbah_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Shemot_Rabbah_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Weekday_Siddur_Sefard_Linear_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Weekday_Siddur_Sefard_Linear_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Machzor_Yom_Kippur_Sefard_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Machzor_Yom_Kippur_Sefard_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Otzar_Midrashim_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Otzar_Midrashim_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Siddur_Sefard_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Siddur_Sefard_clean_concatenated.txt.json saved.\n",
      "--- Processing of GT Mishnah_Bava_Batra_clean_concatenated.txt ---\n",
      "    File lines_dict_with_alg_GT/lines_dict_with_alg_Mishnah_Bava_Batra_clean_concatenated.txt.json saved.\n",
      "XML files in xmls_for_eSc/Mishnah_Kiddushin_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Kiddushin_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Yalkut_Shimoni_on_Nach_clean_concatenated.txt compressed in xmls_for_eSc/Yalkut_Shimoni_on_Nach_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/MT_NoVoc_concatenated.txt compressed in xmls_for_eSc/MT_NoVoc_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Pirkei_Avot_clean_concatenated.txt compressed in xmls_for_eSc/Pirkei_Avot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Shekalim_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Shekalim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Hadran_for_Tanakh_clean_concatenated.txt compressed in xmls_for_eSc/Hadran_for_Tanakh_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Ruth_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Ruth_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Rosh_Hashanah_Ashkenaz_Linear_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Rosh_Hashanah_Ashkenaz_Linear_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Tanchuma_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Tanchuma_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Ma'aneh_Lashon_Chabad_clean_concatenated.txt compressed in xmls_for_eSc/Ma'aneh_Lashon_Chabad_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Kelim_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Kelim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Rosh_Hashanah_Sefard_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Rosh_Hashanah_Sefard_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Tehillim_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Tehillim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Birkat_Hamazon_clean_concatenated.txt compressed in xmls_for_eSc/Birkat_Hamazon_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Esther_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Esther_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Tikkun_HaKlali_clean_concatenated.txt compressed in xmls_for_eSc/Tikkun_HaKlali_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Makhshirin_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Makhshirin_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Megillah_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Megillah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Seder_Olam_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Seder_Olam_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Weekday_Siddur_Chabad_clean_concatenated.txt compressed in xmls_for_eSc/Weekday_Siddur_Chabad_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Shabbat_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Shabbat_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Rosh_Hashanah_Edot_HaMizrach_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Rosh_Hashanah_Edot_HaMizrach_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Yevamot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Yevamot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Ein_Yaakov_clean_concatenated.txt compressed in xmls_for_eSc/Ein_Yaakov_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Sifrei_Bamidbar_clean_concatenated.txt compressed in xmls_for_eSc/Sifrei_Bamidbar_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Bamidbar_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Bamidbar_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Sanhedrin_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Sanhedrin_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnat_Rabbi_Eliezer_clean_concatenated.txt compressed in xmls_for_eSc/Mishnat_Rabbi_Eliezer_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Pirkei_DeRabbi_Eliezer_clean_concatenated.txt compressed in xmls_for_eSc/Pirkei_DeRabbi_Eliezer_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Aggadat_Bereshit_clean_concatenated.txt compressed in xmls_for_eSc/Aggadat_Bereshit_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Pesach_Haggadah_clean_concatenated.txt compressed in xmls_for_eSc/Pesach_Haggadah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Zevachim_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Zevachim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Talmud_Jerusalem.txt compressed in xmls_for_eSc/Talmud_Jerusalem.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Makkot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Makkot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Lekha_Dodi_clean_concatenated.txt compressed in xmls_for_eSc/Lekha_Dodi_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Shevuot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Shevuot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Sekhel_Tov_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Sekhel_Tov_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Ruth_Rabbah_(Lerner)_clean_concatenated.txt compressed in xmls_for_eSc/Ruth_Rabbah_(Lerner)_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Middot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Middot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Talmud_Babylon.txt compressed in xmls_for_eSc/Talmud_Babylon.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Sifrei_Aggadah_on_Esther_clean_concatenated.txt compressed in xmls_for_eSc/Sifrei_Aggadah_on_Esther_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Shir_HaShirim_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Shir_HaShirim_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Tanna_DeBei_Eliyahu_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Tanna_DeBei_Eliyahu_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Yalkut_Shimoni_on_Torah_clean_concatenated.txt compressed in xmls_for_eSc/Yalkut_Shimoni_on_Torah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Ein_Yaakov_(Glick_Edition)_clean_concatenated.txt compressed in xmls_for_eSc/Ein_Yaakov_(Glick_Edition)_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Keter_Malkhut_clean_concatenated.txt compressed in xmls_for_eSc/Keter_Malkhut_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Devarim_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Devarim_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Peah_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Peah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Perek_Shirah_clean_concatenated.txt compressed in xmls_for_eSc/Perek_Shirah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Kabbalat_Shabbat_clean_concatenated.txt compressed in xmls_for_eSc/Kabbalat_Shabbat_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Terumot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Terumot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Shabbat_Siddur_Sefard_Linear_clean_concatenated.txt compressed in xmls_for_eSc/Shabbat_Siddur_Sefard_Linear_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Bereshit_Rabbati_clean_concatenated.txt compressed in xmls_for_eSc/Bereshit_Rabbati_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Eduyot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Eduyot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Bava_Kamma_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Bava_Kamma_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Leshon_Chakhamim_clean_concatenated.txt compressed in xmls_for_eSc/Leshon_Chakhamim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Tanchuma_Buber_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Tanchuma_Buber_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Pesach_Haggadah_Edot_Hamizrah_clean_concatenated.txt compressed in xmls_for_eSc/Pesach_Haggadah_Edot_Hamizrah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Siddur_Edot_HaMizrach_clean_concatenated.txt compressed in xmls_for_eSc/Siddur_Edot_HaMizrach_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Pesikta_Rabbati_clean_concatenated.txt compressed in xmls_for_eSc/Pesikta_Rabbati_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Tannaim_on_Deuteronomy_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Tannaim_on_Deuteronomy_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Shir_HaKavod_clean_concatenated.txt compressed in xmls_for_eSc/Shir_HaKavod_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Negaim_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Negaim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Hallel_clean_concatenated.txt compressed in xmls_for_eSc/Hallel_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Vayikra_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Vayikra_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Tanna_debei_Eliyahu_Zuta_clean_concatenated.txt compressed in xmls_for_eSc/Tanna_debei_Eliyahu_Zuta_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Mishlei_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Mishlei_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Seder_Ma'amadot_clean_concatenated.txt compressed in xmls_for_eSc/Seder_Ma'amadot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Nedarim_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Nedarim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Pesikta_DeRav_Kahana_clean_concatenated.txt compressed in xmls_for_eSc/Pesikta_DeRav_Kahana_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Shmuel_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Shmuel_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Sifrei_Devarim_clean_concatenated.txt compressed in xmls_for_eSc/Sifrei_Devarim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Yelamdenu,_Selections_from_Yalkut_Talmud_Torah_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Yelamdenu,_Selections_from_Yalkut_Talmud_Torah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mekhilta_DeRabbi_Shimon_Ben_Yochai_clean_concatenated.txt compressed in xmls_for_eSc/Mekhilta_DeRabbi_Shimon_Ben_Yochai_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Yom_Kippur_Edot_HaMizrach_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Yom_Kippur_Edot_HaMizrach_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Sefer_HaYashar_(midrash)_clean_concatenated.txt compressed in xmls_for_eSc/Sefer_HaYashar_(midrash)_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Berakhot_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Berakhot_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Gittin_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Gittin_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Sotah_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Sotah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Bereshit_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Bereshit_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Selichot_Edot_HaMizrach_clean_concatenated.txt compressed in xmls_for_eSc/Selichot_Edot_HaMizrach_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Midrash_Lekach_Tov_on_Ruth_clean_concatenated.txt compressed in xmls_for_eSc/Midrash_Lekach_Tov_on_Ruth_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Niddah_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Niddah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Ta'anit_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Ta'anit_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Kohelet_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Kohelet_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Hadran_clean_concatenated.txt compressed in xmls_for_eSc/Hadran_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Seder_Tisha_B'Av_(Edot_HaMizrach)_clean_concatenated.txt compressed in xmls_for_eSc/Seder_Tisha_B'Av_(Edot_HaMizrach)_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Bava_Batra_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Bava_Batra_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Eruvin_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Eruvin_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Eikhah_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Eikhah_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Yom_Kippur_Ashkenaz_Linear_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Yom_Kippur_Ashkenaz_Linear_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mekhilta_DeRabbi_Yishmael_clean_concatenated.txt compressed in xmls_for_eSc/Mekhilta_DeRabbi_Yishmael_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Siddur_Ashkenaz_clean_concatenated.txt compressed in xmls_for_eSc/Siddur_Ashkenaz_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Sifrei_Zuta_clean_concatenated.txt compressed in xmls_for_eSc/Sifrei_Zuta_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Sifra_clean_concatenated.txt compressed in xmls_for_eSc/Sifra_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Shemot_Rabbah_clean_concatenated.txt compressed in xmls_for_eSc/Shemot_Rabbah_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Weekday_Siddur_Sefard_Linear_clean_concatenated.txt compressed in xmls_for_eSc/Weekday_Siddur_Sefard_Linear_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Machzor_Yom_Kippur_Sefard_clean_concatenated.txt compressed in xmls_for_eSc/Machzor_Yom_Kippur_Sefard_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Otzar_Midrashim_clean_concatenated.txt compressed in xmls_for_eSc/Otzar_Midrashim_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Siddur_Sefard_clean_concatenated.txt compressed in xmls_for_eSc/Siddur_Sefard_clean_concatenated.txt_alignment.zip\n",
      "XML files in xmls_for_eSc/Mishnah_Tamid_clean_concatenated.txt compressed in xmls_for_eSc/Mishnah_Tamid_clean_concatenated.txt_alignment.zip\n"
     ]
    }
   ],
   "source": [
    "# run the complete pipeline\n",
    "extract_passim_results(path_passim_output)\n",
    "process_alignment_xml_as_txt(path_alg_dicts, path_xmls_for_eSc, path_xmls_from_eSc, levenshtein_threshold)\n",
    "alignment_register = load_alignment_register(alignment_register_path=\"alignment_register/alignment_register.json\")\n",
    "create_tsv_from_alignment_register(alignment_register,doc_pk, display_n_best_gt=True, n_best_gt=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d14c18",
   "metadata": {},
   "source": [
    "### Find the best GTs for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f41c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_n_best_gt(image_name, n_best_gt):\n",
    "    \"\"\"\n",
    "    Function to get the n best GT for a specific image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_name: name of the image (filename without extension)\n",
    "    - n_best_gt: number of best GTs to retrieve (default is 3)\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples containing the n best GTs for the specified image, where each tuple\n",
    "      contains the GT id and the number of aligned lines.\n",
    "    - If no data is found for the image, returns a string indicating so.\n",
    "    \"\"\"\n",
    "    # keep the image name as entered by the user for the output message\n",
    "    user_image_name = image_name\n",
    "\n",
    "    # Remove the file extension\n",
    "    image_name, extension = os.path.splitext(image_name)\n",
    "\n",
    "    # Remove the \".xml\" extension if present\n",
    "    image_name = image_name + \".xml\" if not image_name.endswith(\".xml\") else image_name\n",
    "    \n",
    "    alignment_register = load_alignment_register('alignment_register/alignment_register.json')\n",
    "    aligned_counts_by_image = create_aligned_counts_by_image(alignment_register)\n",
    "    top_n_best_gt = identify_top_n_best_gt(aligned_counts_by_image, n_best_gt)\n",
    "    \n",
    "    # Trouver les n meilleurs GT pour l'image spécifiée\n",
    "    if image_name in top_n_best_gt:\n",
    "        top_gt_list = top_n_best_gt[image_name]\n",
    "        print(f\"Top {n_best_gt} GTs for image {image_name}:\")\n",
    "        for i, (gt_id, aligned_lines_count) in enumerate(top_gt_list, start=1):\n",
    "            print(f\"\\tTop {i} GT: {gt_id} with {aligned_lines_count} alignments\")\n",
    "        return top_gt_list\n",
    "    else:\n",
    "        return f\"No data found for image {user_image_name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f980288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 GTs for image IE87726132_00023.xml:\n",
      "\tTop 1 GT: MT_NoVoc_concatenated.txt with 22 alignments\n",
      "\tTop 2 GT: Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt with 14 alignments\n",
      "\tTop 3 GT: Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt with 14 alignments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('MT_NoVoc_concatenated.txt', 22),\n",
       " ('Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt', 14),\n",
       " ('Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt', 14)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_image_n_best_gt('IE87726132_00023.png', n_best_gt=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46d9f3",
   "metadata": {},
   "source": [
    "### Importing altos in eScriptorium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc50d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary functions and packages for the eScriptorium API\n",
    "from functions import *\n",
    "from packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca3c7527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 b'{\"status\":\"ok\"}'\n",
      "Aggadat_Bereshit_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Bamidbar_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Bereshit_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Bereshit_Rabbati_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Birkat_Hamazon_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Hallel_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Kabbalat_Shabbat_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Keter_Malkhut_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Kohelet_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Lekha_Dodi_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Leshon_Chakhamim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Negaim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Niddah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Peah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Sanhedrin_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Shabbat_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Shekalim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Shevuot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Sotah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Ta'anit_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Tamid_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Terumot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Yom_Kippur_Edot_HaMizrach_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Yom_Kippur_Sefard_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mekhilta_DeRabbi_Shimon_Ben_Yochai_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mekhilta_DeRabbi_Yishmael_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Lekach_Tov_on_Ruth_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Mishlei_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Seder_Olam_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Seder_Tisha_B'Av_(Edot_HaMizrach)_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Sefer_HaYashar_(midrash)_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Selichot_Edot_HaMizrach_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Shabbat_Siddur_Sefard_Linear_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Shemot_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Shir_HaKavod_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Yevamot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Zevachim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnat_Rabbi_Eliezer_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "MT_NoVoc_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Otzar_Midrashim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Perek_Shirah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Devarim_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Sekhel_Tov_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Pesach_Haggadah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Yelamdenu,_Selections_from_Yalkut_Talmud_Torah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Bava_Batra_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Bava_Kamma_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Berakhot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Eduyot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Eruvin_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Gittin_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Kelim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Sifrei_Devarim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Sifrei_Zuta_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Talmud_Babylon.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Talmud_Jerusalem.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Tanna_DeBei_Eliyahu_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Tanna_debei_Eliyahu_Zuta_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Pesach_Haggadah_Edot_Hamizrah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Pesikta_DeRav_Kahana_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Pesikta_Rabbati_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Pirkei_Avot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Pirkei_DeRabbi_Eliezer_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Ruth_Rabbah_(Lerner)_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Ruth_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Seder_Ma'amadot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Kiddushin_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Makhshirin_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Makkot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Megillah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Middot_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Mishnah_Nedarim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Ma'aneh_Lashon_Chabad_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Rosh_Hashanah_Ashkenaz_Linear_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Rosh_Hashanah_Edot_HaMizrach_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Rosh_Hashanah_Sefard_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Machzor_Yom_Kippur_Ashkenaz_Linear_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Shir_HaShirim_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Siddur_Ashkenaz_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Siddur_Edot_HaMizrach_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Siddur_Sefard_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Sifra_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Sifrei_Aggadah_on_Esther_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Sifrei_Bamidbar_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Eikhah_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Ein_Yaakov_(Glick_Edition)_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Ein_Yaakov_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Esther_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Hadran_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Hadran_for_Tanakh_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Shmuel_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Tanchuma_Buber_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Tanchuma_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Tannaim_on_Deuteronomy_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Midrash_Tehillim_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Tikkun_HaKlali_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Vayikra_Rabbah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Weekday_Siddur_Chabad_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Weekday_Siddur_Sefard_Linear_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Yalkut_Shimoni_on_Nach_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "200 b'{\"status\":\"ok\"}'\n",
      "Yalkut_Shimoni_on_Torah_clean_concatenated.txt_alignment.zip has been successfully imported into eScriptorium.\n",
      "Link do the document in eScriptorium: https://msia.escriptorium.fr/document/4518/images/\n"
     ]
    }
   ],
   "source": [
    "# Insert date + time\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y-%H_%M_%S\")\n",
    "\n",
    "# ZIP and import each file in the folder\n",
    "for zip_filename in os.listdir(path_xmls_for_eSc):\n",
    "    if zip_filename.endswith('.zip'):\n",
    "        # Build the full path to the ZIP file\n",
    "        zip_file_path = os.path.join(path_xmls_for_eSc, zip_filename)\n",
    "        \n",
    "        # name of the alignment file\n",
    "        name = zip_filename.split(\".\")[0]+\"_pip_test_regexp_\" + dt_string\n",
    "        \n",
    "\n",
    "        # Import in eScriptorium\n",
    "        import_xml(doc_pk, path_xmls_for_eSc, zip_filename, name)\n",
    "        \n",
    "        print(f\"{zip_filename} has been successfully imported into eScriptorium.\")\n",
    "\n",
    "print(f\"Link do the document in eScriptorium: https://msia.escriptorium.fr/document/{doc_pk}/images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e1d8d",
   "metadata": {},
   "source": [
    "### Cleaning up the transcription levels in eSc document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8fc145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_active_transcription_levels(doc_pk):\n",
    "    \"\"\"\n",
    "    Display the active transcription levels in a document.\n",
    "    In order to be able to delete them, if necessary.\n",
    "    \"\"\"\n",
    "    active_transcription_level_list = []\n",
    "    # Display the basic information of the document\n",
    "    nu_parts,transcription_level_list,region_type_list,line_type_list = get_basic_info(doc_pk=doc_pk)\n",
    "    print('---')\n",
    "    # Display the pk and the names of the transcriptions in the document, that are not archived\n",
    "    print(f\"Active transcription levels in doc {doc_pk}:\")\n",
    "    for transcription in transcription_level_list:    \n",
    "        if transcription['archived'] == False:\n",
    "            print(f\"\\t{transcription['pk']} {transcription['name']}\")\n",
    "            active_transcription_level_list.append(transcription['pk'])\n",
    "    print(f'list of active transcription levels: {active_transcription_level_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "102a96d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get document segmentation ontology for document:  4381\n",
      "https://msia.escriptorium.fr/api/documents/4381/\n",
      "Document: 4381  with  64  parts\n",
      "region types: [{'pk': 6912, 'name': 'Catchword'}, {'pk': 3, 'name': 'Commentary'}, {'pk': 6910, 'name': 'FooterCentral'}, {'pk': 6914, 'name': 'Handwritten'}, {'pk': 6908, 'name': 'Header'}, {'pk': 4, 'name': 'Illustration'}, {'pk': 2, 'name': 'Main'}, {'pk': 6909, 'name': 'MainCentral'}, {'pk': 6911, 'name': 'Margin'}, {'pk': 6913, 'name': 'RunningHeader'}, {'pk': 1, 'name': 'Title'}]\n",
      "line types: [{'pk': 15289, 'name': 'Handwritten'}, {'pk': 15288, 'name': 'MainCentral'}, {'pk': 15287, 'name': 'NotMain'}]\n",
      "transcription_level_list: [{'pk': 11039, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_15/05/2024-15_38_32', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11037, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_38_32', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11038, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_38_32', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11035, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_38_32', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11036, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_15/05/2024-15_38_32', 'archived': False, 'avg_confidence': 0.986672220664065}, {'pk': 11034, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_15/05/2024-15_29_52', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11032, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_29_52', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11030, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_29_52', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11033, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_29_52', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 11031, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_15/05/2024-15_29_52', 'archived': False, 'avg_confidence': 0.986672220664065}, {'pk': 10801, 'name': 'Sid_Ashk_Daniel_08_7_600', 'archived': True, 'avg_confidence': None}, {'pk': 10888, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_02/05/2024-14_13_13', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10890, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_02/05/2024-14_13_13', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10889, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_02/05/2024-14_13_13', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10891, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_02/05/2024-14_13_13', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10892, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_02/05/2024-14_13_13', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 11006, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_13/05/2024-15_11_30', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 11007, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_13/05/2024-15_11_30', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 11010, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_13/05/2024-15_11_30', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 11008, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_13/05/2024-15_11_30', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 11009, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_13/05/2024-15_11_30', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10796, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenatedpipeline_lev_r_08', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10797, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenatedpipeline_lev_r_08', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10798, 'name': 'MT_NoVoc_concatenatedpipeline_lev_r_08', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10799, 'name': 'Siddur_Ashkenaz_clean_concatenatedpipeline_lev_r_08', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10800, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Danielpipeline_lev_r_08', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10882, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_02/05/2024-13_26_11', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10884, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_02/05/2024-13_26_11', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10883, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_02/05/2024-13_26_11', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10885, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_02/05/2024-13_26_11', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10886, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_02/05/2024-13_26_11', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10857, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_30/04/2024-14_39_23', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10850, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_31_23', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10852, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_30/04/2024-14_31_23', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10851, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_31_23', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10853, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_31_23', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10854, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_30/04/2024-14_31_23', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10855, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_39_23', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10856, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_39_23', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10858, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_39_23', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10859, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_30/04/2024-14_39_23', 'archived': True, 'avg_confidence': 0.9847869869290219}, {'pk': 10847, 'name': 'MT_NoVoc_concatenated_pip_test_regexp_30/04/2024-14_09_29', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10845, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_09_29', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10846, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_09_29', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10848, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_30/04/2024-14_09_29', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10849, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_30/04/2024-14_09_29', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10831, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10833, 'name': 'MT_NoVoc_concatenated_pip_test_regexp', 'archived': True, 'avg_confidence': 0.986672220664065}, {'pk': 10832, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10834, 'name': 'Siddur_Ashkenaz_clean_concatenated_pip_test_regexp', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10835, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp', 'archived': True, 'avg_confidence': 0.9857541317294087}, {'pk': 10765, 'name': 'MT_NoVoc_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10766, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10769, 'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10768, 'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9943613526297779}, {'pk': 10767, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10770, 'name': 'MT_NoVoc_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10771, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10773, 'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9877159627701019}, {'pk': 10774, 'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10772, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10760, 'name': 'MT_NoVoc_concatenated', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10761, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10762, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated', 'archived': True, 'avg_confidence': 0.9943613526297779}, {'pk': 10763, 'name': 'Siddur_Ashkenaz_clean_concatenated', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10764, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10756, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10755, 'name': 'MT_NoVoc_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10758, 'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9943613526297779}, {'pk': 10759, 'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10757, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10754, 'name': 'kraken:sinai_no_voc_61', 'archived': False, 'avg_confidence': 0.9808429843538934}, {'pk': 10753, 'name': 'selection_daniel | export', 'archived': False, 'avg_confidence': 0.9865010420470414}, {'pk': 10752, 'name': 'selection_luigi | export', 'archived': False, 'avg_confidence': 0.979462673228952}, {'pk': 10751, 'name': 'manual', 'archived': False, 'avg_confidence': None}]\n",
      "---\n",
      "Active transcription levels in doc 4381:\n",
      "\t11039 Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_15/05/2024-15_38_32\n",
      "\t11037 Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_38_32\n",
      "\t11038 Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_38_32\n",
      "\t11035 Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_38_32\n",
      "\t11036 MT_NoVoc_concatenated_pip_test_regexp_15/05/2024-15_38_32\n",
      "\t11034 Siddur_Ashkenaz_novoc_no_lbs_Daniel_pip_test_regexp_15/05/2024-15_29_52\n",
      "\t11032 Siddur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_29_52\n",
      "\t11030 Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_29_52\n",
      "\t11033 Machzor_Yom_Kippur_Ashkenaz_clean_concatenated_pip_test_regexp_15/05/2024-15_29_52\n",
      "\t11031 MT_NoVoc_concatenated_pip_test_regexp_15/05/2024-15_29_52\n",
      "\t10754 kraken:sinai_no_voc_61\n",
      "\t10753 selection_daniel | export\n",
      "\t10752 selection_luigi | export\n",
      "\t10751 manual\n",
      "list of active transcription levels: [11039, 11037, 11038, 11035, 11036, 11034, 11032, 11030, 11033, 11031, 10754, 10753, 10752, 10751]\n"
     ]
    }
   ],
   "source": [
    "display_active_transcription_levels(doc_pk=4366)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab5813d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_level_list_to_delete = [11039, 11037, 11038, 11035, 11036, 11034, 11032, 11030, 11033, 11031]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66706191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tr_levels(doc_pk,tr_level_list_to_delete):\n",
    "    \"\"\"\n",
    "    Function to delete a list of transcription layers\n",
    "    from a specific document.\n",
    "    \"\"\"\n",
    "    for tr_level in tr_level_list_to_delete:\n",
    "        delete_url = f\"https://msia.escriptorium.fr/api/documents/{doc_pk}/transcriptions/{tr_level}/\"\n",
    "        r = requests.delete(delete_url, headers=headers)\n",
    "        if r.status_code == 204:\n",
    "            print(f\"Transcription level {tr_level} has been deleted from document {doc_pk}.\")\n",
    "        else:\n",
    "            print(f\"Error: Transcription level {tr_level} could not be deleted from document {doc_pk}.\")\n",
    "            print(r.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "925dacb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription level 11039 has been deleted from document 4381.\n",
      "Transcription level 11037 has been deleted from document 4381.\n",
      "Transcription level 11038 has been deleted from document 4381.\n",
      "Transcription level 11035 has been deleted from document 4381.\n",
      "Transcription level 11036 has been deleted from document 4381.\n",
      "Transcription level 11034 has been deleted from document 4381.\n",
      "Transcription level 11032 has been deleted from document 4381.\n",
      "Transcription level 11030 has been deleted from document 4381.\n",
      "Transcription level 11033 has been deleted from document 4381.\n",
      "Transcription level 11031 has been deleted from document 4381.\n"
     ]
    }
   ],
   "source": [
    "delete_tr_levels(doc_pk,tr_level_list_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf933d",
   "metadata": {},
   "source": [
    "# Exploring the alignment register with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4dbaa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('alignment_register/alignment_register.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a778e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>aligned_lines_count</th>\n",
       "      <th>GT_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IE34120895_00033.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IE35481905_00027.xml</td>\n",
       "      <td>0</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IE61220167_00084.xml</td>\n",
       "      <td>9</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IE87234800_00004.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IE87234800_00005.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  aligned_lines_count  \\\n",
       "0  IE34120895_00033.xml                    0   \n",
       "1  IE35481905_00027.xml                    0   \n",
       "2  IE61220167_00084.xml                    9   \n",
       "3  IE87234800_00004.xml                   17   \n",
       "4  IE87234800_00005.xml                   22   \n",
       "\n",
       "                                               GT_id  \n",
       "0  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "1  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "2  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "3  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "4  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eefb9ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>aligned_lines_count</th>\n",
       "      <th>GT_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IE61220167_00084.xml</td>\n",
       "      <td>9</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IE87234800_00004.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IE87234800_00005.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IE87363222_00008.xml</td>\n",
       "      <td>13</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IE87447950_00011.xml</td>\n",
       "      <td>12</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>IE87752740_00022.xml</td>\n",
       "      <td>13</td>\n",
       "      <td>Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>IE87752740_00038.xml</td>\n",
       "      <td>10</td>\n",
       "      <td>Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>IE87755510_00024.xml</td>\n",
       "      <td>16</td>\n",
       "      <td>Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>IE87555665_00021.xml</td>\n",
       "      <td>6</td>\n",
       "      <td>Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>IE87708411_00019.xml</td>\n",
       "      <td>11</td>\n",
       "      <td>Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  aligned_lines_count  \\\n",
       "2    IE61220167_00084.xml                    9   \n",
       "3    IE87234800_00004.xml                   17   \n",
       "4    IE87234800_00005.xml                   22   \n",
       "6    IE87363222_00008.xml                   13   \n",
       "7    IE87447950_00011.xml                   12   \n",
       "..                    ...                  ...   \n",
       "200  IE87752740_00022.xml                   13   \n",
       "201  IE87752740_00038.xml                   10   \n",
       "202  IE87755510_00024.xml                   16   \n",
       "204  IE87555665_00021.xml                    6   \n",
       "205  IE87708411_00019.xml                   11   \n",
       "\n",
       "                                                 GT_id  \n",
       "2    Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "3    Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "4    Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "6    Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "7    Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "..                                                 ...  \n",
       "200            Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt  \n",
       "201            Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt  \n",
       "202            Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt  \n",
       "204            Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt  \n",
       "205            Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt  \n",
       "\n",
       "[165 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display le lines where GT_ID is 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated'\n",
    "df[df['GT_id'] == 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated']\n",
    "\n",
    "# sort by number of aligned lines\n",
    "df.sort_values(by='aligned_lines_count', ascending=False)\n",
    "\n",
    "# display files with more than 5 lines aligned\n",
    "df[df['aligned_lines_count'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b5f0175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt',\n",
       "       'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated.txt',\n",
       "       'MT_NoVoc_concatenated.txt',\n",
       "       'Siddur_Ashkenaz_clean_concatenated.txt',\n",
       "       'Siddur_Ashkenaz_novoc_no_lbs_Daniel.txt'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display GT_id values\n",
    "df['GT_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "931b63c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "https://msia.escriptorium.fr/document/4381/part/None/edit\n"
     ]
    }
   ],
   "source": [
    "part_pk = next((item['pk'] for item in all_parts if item['filename'] == 'IE87532920_00033.jpg'), None)\n",
    "print(part_pk)\n",
    "print(f\"https://msia.escriptorium.fr/document/{doc_pk}/part/{part_pk}/edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f19a8577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>aligned_lines_count</th>\n",
       "      <th>GT_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IE87474895_00044.xml</td>\n",
       "      <td>27</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>IE87582245_00015.xml</td>\n",
       "      <td>23</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IE87447950_00015.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>IE87744435_00039.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>IE87708411_00021.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IE87234800_00005.xml</td>\n",
       "      <td>22</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>IE87744435_00015.xml</td>\n",
       "      <td>21</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IE87580382_00041.xml</td>\n",
       "      <td>20</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IE87502633_00044.xml</td>\n",
       "      <td>20</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IE87447950_00018.xml</td>\n",
       "      <td>20</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IE87581919_00016.xml</td>\n",
       "      <td>19</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IE87234800_00004.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>IE87755510_00024.xml</td>\n",
       "      <td>15</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IE87532920_00026.xml</td>\n",
       "      <td>15</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IE87726132_00023.xml</td>\n",
       "      <td>14</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IE87363222_00008.xml</td>\n",
       "      <td>13</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IE87581919_00018.xml</td>\n",
       "      <td>13</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>IE87752740_00022.xml</td>\n",
       "      <td>12</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IE87447950_00011.xml</td>\n",
       "      <td>12</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>IE87752740_00019.xml</td>\n",
       "      <td>11</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IE87705971_00006.xml</td>\n",
       "      <td>11</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>IE87705976_00036.xml</td>\n",
       "      <td>11</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IE87502633_00018.xml</td>\n",
       "      <td>10</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IE61220167_00084.xml</td>\n",
       "      <td>9</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>IE87705976_00034.xml</td>\n",
       "      <td>9</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>IE87708411_00019.xml</td>\n",
       "      <td>9</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>IE87719995_00046.xml</td>\n",
       "      <td>8</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>IE87719995_00053.xml</td>\n",
       "      <td>8</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>IE87716931_00014.xml</td>\n",
       "      <td>8</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>IE87717323_00012.xml</td>\n",
       "      <td>6</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IE87610546_00015.xml</td>\n",
       "      <td>6</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IE87580382_00008.xml</td>\n",
       "      <td>5</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IE87474895_00014.xml</td>\n",
       "      <td>4</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IE87297122_00014.xml</td>\n",
       "      <td>2</td>\n",
       "      <td>Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  aligned_lines_count  \\\n",
       "11  IE87474895_00044.xml                   27   \n",
       "19  IE87582245_00015.xml                   23   \n",
       "8   IE87447950_00015.xml                   22   \n",
       "35  IE87744435_00039.xml                   22   \n",
       "26  IE87708411_00021.xml                   22   \n",
       "4   IE87234800_00005.xml                   22   \n",
       "34  IE87744435_00015.xml                   21   \n",
       "16  IE87580382_00041.xml                   20   \n",
       "13  IE87502633_00044.xml                   20   \n",
       "9   IE87447950_00018.xml                   20   \n",
       "17  IE87581919_00016.xml                   19   \n",
       "3   IE87234800_00004.xml                   17   \n",
       "38  IE87755510_00024.xml                   15   \n",
       "14  IE87532920_00026.xml                   15   \n",
       "31  IE87726132_00023.xml                   14   \n",
       "6   IE87363222_00008.xml                   13   \n",
       "18  IE87581919_00018.xml                   13   \n",
       "37  IE87752740_00022.xml                   12   \n",
       "7   IE87447950_00011.xml                   12   \n",
       "36  IE87752740_00019.xml                   11   \n",
       "23  IE87705971_00006.xml                   11   \n",
       "25  IE87705976_00036.xml                   11   \n",
       "12  IE87502633_00018.xml                   10   \n",
       "2   IE61220167_00084.xml                    9   \n",
       "24  IE87705976_00034.xml                    9   \n",
       "39  IE87708411_00019.xml                    9   \n",
       "29  IE87719995_00046.xml                    8   \n",
       "30  IE87719995_00053.xml                    8   \n",
       "27  IE87716931_00014.xml                    8   \n",
       "28  IE87717323_00012.xml                    6   \n",
       "20  IE87610546_00015.xml                    6   \n",
       "15  IE87580382_00008.xml                    5   \n",
       "10  IE87474895_00014.xml                    4   \n",
       "5   IE87297122_00014.xml                    2   \n",
       "\n",
       "                                                GT_id  \n",
       "11  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "19  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "8   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "35  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "26  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "4   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "34  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "16  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "13  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "9   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "17  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "3   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "38  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "14  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "31  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "6   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "18  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "37  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "7   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "36  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "23  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "25  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "12  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "2   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "24  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "39  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "29  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "30  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "27  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "28  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "20  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "15  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "10  Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  \n",
       "5   Machzor_Rosh_Hashanah_Ashkenaz_clean_concatena...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display files where GT_ID is 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated' and aligned_lines_count > 5\n",
    "df[(df['GT_id'] == 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated.txt') & (df['aligned_lines_count'] > 1)].sort_values(by='aligned_lines_count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec83ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\"IE87755510_00024.jpg\", \"IE87752740_00038.jpg\", \"IE87752740_00022.jpg\", \"IE87752740_00019.jpg\", \"IE87744435_00039.jpg\", \"IE87744435_00015.jpg\", \"IE87739615_00009.jpg\", \"IE87733114_00008.jpg\", \"IE87733114_00007.jpg\", \"IE87733114_00006.jpg\", \"IE87726132_00023.jpg\", \"IE87719995_00053.jpg\", \"IE87719995_00046.jpg\", \"IE87717323_00012.jpg\", \"IE87716931_00014.jpg\", \"IE87708411_00021.jpg\", \"IE87708411_00019.jpg\", \"IE87705976_00036.jpg\", \"IE87705976_00034.jpg\", \"IE87705971_00006.jpg\", \"IE87700963_00014.jpg\", \"IE87694978_00020.jpg\", \"IE87690674_00007.jpg\", \"IE87675634_00010.jpg\", \"IE87675634_00007.jpg\", \"IE87610546_00015.jpg\", \"IE87582245_00015.jpg\", \"IE87581919_00018.jpg\", \"IE87581919_00016.jpg\", \"IE87581919_00011.jpg\", \"IE87580382_00041.jpg\", \"IE87580382_00008.jpg\", \"IE87555665_00021.jpg\", \"IE87532920_00026.jpg\", \"IE87519524_00013.jpg\", \"IE87508468_00031.jpg\", \"IE87502633_00044.jpg\", \"IE87502633_00018.jpg\", \"IE87476216_00051.jpg\", \"IE87474895_00044.jpg\", \"IE87474895_00014.jpg\", \"IE87447950_00018.jpg\", \"IE87447950_00015.jpg\", \"IE87447950_00011.jpg\", \"IE87363222_00008.jpg\", \"IE87297122_00014.jpg\", \"IE87234800_00005.jpg\", \"IE87234800_00004.jpg\", \"IE87234800_00003.jpg\"]\n",
    "doc_pk = 4381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b42d61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[734798, 734797, 734796, 734795, 734794, 734793, 734792, 734791, 734790, 734789, 734788, 734787, 734786, 734785, 734784, 734783, 734782, 734781, 734780, 734779, 734778, 734777, 734776, 734775, 734774, 734773, 734772, 734771, 734770, 734769, 734768, 734767, 734766, 734765, 734764, 734763, 734762, 734761, 734760, 734759, 734758, 734757, 734756, 734755, 734754, 734753, 734752, 734751, 734750]\n"
     ]
    }
   ],
   "source": [
    "all_parts = get_all_parts(doc_pk)\n",
    "\n",
    "part_pk_list = []\n",
    "for picture in list:\n",
    "    part_pk = next((item['pk'] for item in all_parts if item['filename'] == picture), None)\n",
    "    part_pk_list.append(part_pk)\n",
    "print(part_pk_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a329d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(part_pk_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95fd078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get document segmentation ontology for document:  4381\n",
      "https://msia.escriptorium.fr/api/documents/4381/\n",
      "Document: 4381  with  64  parts\n",
      "region types: [{'pk': 6912, 'name': 'Catchword'}, {'pk': 3, 'name': 'Commentary'}, {'pk': 6910, 'name': 'FooterCentral'}, {'pk': 6914, 'name': 'Handwritten'}, {'pk': 6908, 'name': 'Header'}, {'pk': 4, 'name': 'Illustration'}, {'pk': 2, 'name': 'Main'}, {'pk': 6909, 'name': 'MainCentral'}, {'pk': 6911, 'name': 'Margin'}, {'pk': 6913, 'name': 'RunningHeader'}, {'pk': 1, 'name': 'Title'}]\n",
      "line types: [{'pk': 15289, 'name': 'Handwritten'}, {'pk': 15288, 'name': 'MainCentral'}, {'pk': 15287, 'name': 'NotMain'}]\n",
      "transcription_level_list: [{'pk': 10801, 'name': 'Sid_Ashk_Daniel_08_7_600', 'archived': False, 'avg_confidence': None}, {'pk': 10800, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Danielpipeline_lev_r_08', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 10799, 'name': 'Siddur_Ashkenaz_clean_concatenatedpipeline_lev_r_08', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 10797, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenatedpipeline_lev_r_08', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 10798, 'name': 'MT_NoVoc_concatenatedpipeline_lev_r_08', 'archived': False, 'avg_confidence': 0.986672220664065}, {'pk': 10796, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenatedpipeline_lev_r_08', 'archived': False, 'avg_confidence': 0.9847869869290219}, {'pk': 10765, 'name': 'MT_NoVoc_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10766, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10769, 'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10768, 'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9943613526297779}, {'pk': 10767, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_08', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10770, 'name': 'MT_NoVoc_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10771, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10773, 'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9877159627701019}, {'pk': 10774, 'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10772, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_05', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10760, 'name': 'MT_NoVoc_concatenated', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10761, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10762, 'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated', 'archived': True, 'avg_confidence': 0.9943613526297779}, {'pk': 10763, 'name': 'Siddur_Ashkenaz_clean_concatenated', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10764, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10756, 'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9793586205033695}, {'pk': 10755, 'name': 'MT_NoVoc_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9790699318765446}, {'pk': 10758, 'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9943613526297779}, {'pk': 10759, 'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9815089606972657}, {'pk': 10757, 'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_083', 'archived': True, 'avg_confidence': 0.9810431016590629}, {'pk': 10754, 'name': 'kraken:sinai_no_voc_61', 'archived': False, 'avg_confidence': 0.9808429843538934}, {'pk': 10753, 'name': 'selection_daniel | export', 'archived': False, 'avg_confidence': 0.9865010420470414}, {'pk': 10752, 'name': 'selection_luigi | export', 'archived': False, 'avg_confidence': 0.979462673228952}, {'pk': 10751, 'name': 'manual', 'archived': False, 'avg_confidence': None}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64,\n",
       " [{'pk': 10801,\n",
       "   'name': 'Sid_Ashk_Daniel_08_7_600',\n",
       "   'archived': False,\n",
       "   'avg_confidence': None},\n",
       "  {'pk': 10800,\n",
       "   'name': 'Siddur_Ashkenaz_novoc_no_lbs_Danielpipeline_lev_r_08',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.9847869869290219},\n",
       "  {'pk': 10799,\n",
       "   'name': 'Siddur_Ashkenaz_clean_concatenatedpipeline_lev_r_08',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.9847869869290219},\n",
       "  {'pk': 10797,\n",
       "   'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenatedpipeline_lev_r_08',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.9847869869290219},\n",
       "  {'pk': 10798,\n",
       "   'name': 'MT_NoVoc_concatenatedpipeline_lev_r_08',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.986672220664065},\n",
       "  {'pk': 10796,\n",
       "   'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenatedpipeline_lev_r_08',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.9847869869290219},\n",
       "  {'pk': 10765,\n",
       "   'name': 'MT_NoVoc_pipeline_lev_ratio_08',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9790699318765446},\n",
       "  {'pk': 10766,\n",
       "   'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_08',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9793586205033695},\n",
       "  {'pk': 10769,\n",
       "   'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_08',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9815089606972657},\n",
       "  {'pk': 10768,\n",
       "   'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_08',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9943613526297779},\n",
       "  {'pk': 10767,\n",
       "   'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_08',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9810431016590629},\n",
       "  {'pk': 10770,\n",
       "   'name': 'MT_NoVoc_pipeline_lev_ratio_05',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9790699318765446},\n",
       "  {'pk': 10771,\n",
       "   'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_05',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9793586205033695},\n",
       "  {'pk': 10773,\n",
       "   'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_05',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9877159627701019},\n",
       "  {'pk': 10774,\n",
       "   'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_05',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9815089606972657},\n",
       "  {'pk': 10772,\n",
       "   'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_05',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9810431016590629},\n",
       "  {'pk': 10760,\n",
       "   'name': 'MT_NoVoc_concatenated',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9790699318765446},\n",
       "  {'pk': 10761,\n",
       "   'name': 'Machzor_Rosh_Hashanah_Ashkenaz_clean_concatenated',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9793586205033695},\n",
       "  {'pk': 10762,\n",
       "   'name': 'Machzor_Yom_Kippur_Ashkenaz_clean_concatenated',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9943613526297779},\n",
       "  {'pk': 10763,\n",
       "   'name': 'Siddur_Ashkenaz_clean_concatenated',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9815089606972657},\n",
       "  {'pk': 10764,\n",
       "   'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9810431016590629},\n",
       "  {'pk': 10756,\n",
       "   'name': 'Machzor_Rosh_Hashanah_Ashkenaz_pipeline_lev_ratio_083',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9793586205033695},\n",
       "  {'pk': 10755,\n",
       "   'name': 'MT_NoVoc_pipeline_lev_ratio_083',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9790699318765446},\n",
       "  {'pk': 10758,\n",
       "   'name': 'Machzor_Yom_Kippur_Ashkenaz_pipeline_lev_ratio_083',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9943613526297779},\n",
       "  {'pk': 10759,\n",
       "   'name': 'Siddur_Ashkenaz_pipeline_lev_ratio_083',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9815089606972657},\n",
       "  {'pk': 10757,\n",
       "   'name': 'Siddur_Ashkenaz_novoc_no_lbs_Daniel_pipeline_lev_ratio_083',\n",
       "   'archived': True,\n",
       "   'avg_confidence': 0.9810431016590629},\n",
       "  {'pk': 10754,\n",
       "   'name': 'kraken:sinai_no_voc_61',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.9808429843538934},\n",
       "  {'pk': 10753,\n",
       "   'name': 'selection_daniel | export',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.9865010420470414},\n",
       "  {'pk': 10752,\n",
       "   'name': 'selection_luigi | export',\n",
       "   'archived': False,\n",
       "   'avg_confidence': 0.979462673228952},\n",
       "  {'pk': 10751, 'name': 'manual', 'archived': False, 'avg_confidence': None}],\n",
       " [{'pk': 6912, 'name': 'Catchword'},\n",
       "  {'pk': 3, 'name': 'Commentary'},\n",
       "  {'pk': 6910, 'name': 'FooterCentral'},\n",
       "  {'pk': 6914, 'name': 'Handwritten'},\n",
       "  {'pk': 6908, 'name': 'Header'},\n",
       "  {'pk': 4, 'name': 'Illustration'},\n",
       "  {'pk': 2, 'name': 'Main'},\n",
       "  {'pk': 6909, 'name': 'MainCentral'},\n",
       "  {'pk': 6911, 'name': 'Margin'},\n",
       "  {'pk': 6913, 'name': 'RunningHeader'},\n",
       "  {'pk': 1, 'name': 'Title'}],\n",
       " [{'pk': 15289, 'name': 'Handwritten'},\n",
       "  {'pk': 15288, 'name': 'MainCentral'},\n",
       "  {'pk': 15287, 'name': 'NotMain'}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_basic_info(doc_pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8e769c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "b'{\"status\":\"ok\"}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the transcription level\n",
    "tr_level_pk = 10678\n",
    "# Choose the region type\n",
    "region_type_pk_list = [6798]\n",
    "\n",
    "\n",
    "# get the xmls of the parts from eScriptorium\n",
    "export_xml(doc_pk,part_pk_list,tr_level_pk,region_type_pk_list,include_undefined = False, include_orphan = False, file_format = 'alto',include_images = True, print_status = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
