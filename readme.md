This repository is a work in progress.
Scheduled delivery date: 06/25/2024
# Aligning large quantities of digital text with large numbers of documents

## Pipeline purpose
The function of the scripts in this repository is to enable the alignment of known digital texts with large numbers of digitized manuscripts or prints.

To improve a character recognition model, it is necessary to train it by providing it with transcribed lines of textual content.
This method is expansive in terms of time and human resources.

By aligning digital texts with manuscript images, it is possible to reduce the cost of training a character recognition model.

The principle is as follows:
- textual content is extracted from manuscript images using Kraken OCR software (integrated into eScriptorium).
- Using algorithmic tools like Passim, the extracted text is compared with multiple known digital texts that constitute the ground truth (GT).
- When matches are found between OCR and GT, the two texts are aligned.
- A character recognition model can then be trained on these alignments, avoiding the need to manually transcribe text from manuscript images.

The aim of this pipeline is therefore to align large numbers of known numerical texts with large numbers of documents.
  

## Pipeline steps

1. First, Kraken is used to extract text from manuscript images. This is done in eScriptorium.

2. The extracted texts are retrieved in alto xml files generated by eScriptorium, one file per image. The choice of image batch (documents) and regions to be processed (like: 'Main Central', 'Main Left') is made in the '1_retrieving_xmls_from_eSc.ipynb' script, which retrieves the xml alto files from a local folder by requesting the eScriptorium API.

3. These files are then prepared for alignment in the '2_preparing_xmls_for_alignment.ipynb' script. This notebook is used to create a jsonl file, containing the texts extracted from the images, as well as known numerical texts (GT).
The OCR content of each region to be processed in each image is extracted from the alto xml file, and concatenated into a single character string.
This string is integrated into a dictionary, which also contains a unique identifier for each text block.
To the dictionaries of the text blocks extracted from the images, we add the known numerical texts (GT) to be aligned. These texts come from the Sefaria API. They are retrieved, cleaned and prepared by the script available at this address: https://github.com/Freymat/from_Sefaria_to_Passim.
Finally, the Notebook allows to launch the alignment search with Passim via a subprocess.

4. Alignments are then retrieved and processed in the '3_retrieving_alignments_from_passim.ipynb' script. Alignments considered valid (above a certain Levenshtein threshold) are reintegrated into the alto xml files.
The content of each OCR line is replaced by the aligned text, if valid. The modified alto files are then imported back into eScriptorium via its API.

The alignment result can then be viewed in eScriptorium, where a transcription layer is created by GT.

## To do:

- For each text block (image region), compare valid alignments and identify the best alignment, using a score based on Levenshtein distance.
- Using an index, identify the references of the section selected for alignment, in the known digital text (GT).
- Optimize the code to enable processing of massive quantities of OCR and GT.
